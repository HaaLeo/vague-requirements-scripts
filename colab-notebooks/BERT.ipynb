{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vague-requirements-bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaaLeo/vague-requirements-scripts/blob/engineering%2Fdifferent-preprocessing/colab-notebooks/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgfHNcOPbOk3",
        "colab_type": "text"
      },
      "source": [
        "# Classify requirements as vague or not using [ktrain](https://github.com/amaiya/ktrain) and tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jOLkB2Gyq4e",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies\n",
        "*ktrain* requires TensorFlow 2.1. See [amaiya/ktrain#151](https://github.com/amaiya/ktrain/issues/151).\n",
        "Further we install a forked version of eli5lib to gain insights in the model's decision process and some self built helper functions to preprocess MTurk result files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDBNS4iNXuUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "91855771-9de5-42c4-9f3c-d1228998d452"
      },
      "source": [
        "!pip3 install -q tensorflow_gpu==2.1.0 ktrain==0.17.3\n",
        "!pip3 install -q -U git+https://github.com/HaaLeo/vague-requirements-scripts\n",
        "!pip3 install -q git+https://github.com/amaiya/eli5@tfkeras_0_10_1"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for vaguerequirementslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e1XeYJg3e_8",
        "colab_type": "text"
      },
      "source": [
        "Check versions and enable logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAA46kq4X0C_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b42e325-1bd8-402b-8846-ec17a74c3938"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ktrain\n",
        "assert tf.__version__ == '2.1.0'\n",
        "assert ktrain.__version__ == '0.17.3'\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s [%(threadName)-20.20s] [%(levelname)-5.5s]  %(message)s',\n",
        "    stream=sys.stdout,\n",
        "    level=logging.DEBUG)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-04 16:07:24,878 [MainThread          ] [DEBUG]  Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-2kIx7PwCR5",
        "colab_type": "text"
      },
      "source": [
        "## Set Parameters\n",
        "Set the parameters for this run.\n",
        "Ktrain ignores `max_features` and `ngram_range` in v0.17.3, see [amaiya/ktrain/issues#190](https://github.com/amaiya/ktrain/issues/190)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF_VXFLkwC1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices_to_read = [0,2,3,4] # indicate which MTurk files shall be read.\n",
        "DATA_FILE_NAMES = [f'corpus-batch-{i}-mturk.csv' for i in indices_to_read]\n",
        "\n",
        "RANDOM_STATE = 1 # for seeding\n",
        "\n",
        "LEARNING_RATE = 5e-5\n",
        "EPOCHS = 4\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 6\n",
        "MAX_FEATURES = 35_000\n",
        "NGRAM_RANGE = 1\n",
        "\n",
        "PREPROCESS_MODE = 'distilbert'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdk5lPu3bxze",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl9XSystzRQs",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive\n",
        "Mount the google drive to access the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPQxmvhazWoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3537cdb9-7564-4fed-ad4f-d669642c6478"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4XQHRbHzbb_",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataset Into Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL5yXifL0SEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "outputId": "146e0410-67fd-4701-dae2-be446509e542"
      },
      "source": [
        "from vaguerequirementslib import read_csv_files, build_confusion_matrix, calc_majority_label\n",
        "import pandas as pd\n",
        "\n",
        "def read_drive_data(files_list: list, separator: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate the majority label for the given source file list\n",
        "\n",
        "    Args:\n",
        "        files_list (list): The CSV files to calculate the majority label for\n",
        "        separator (str): The CSV separator\n",
        "        drop_ties (bool): If there is a tie in votes (e.g.: One votes for vague one for not vague) then drop this entry from the confusion matrix.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The dataframe containing the majority label.\n",
        "    \"\"\"\n",
        "    df = read_csv_files(files_list, separator)\n",
        "    confusion_matrix = build_confusion_matrix(df, drop_ties=True)\n",
        "    return calc_majority_label(confusion_matrix)\n",
        "\n",
        "# Read all data\n",
        "df = read_drive_data(\n",
        "    [f'/content/drive/My Drive/datasets/corpus/labeled/{file_name}' for file_name in DATA_FILE_NAMES],\n",
        "    ','\n",
        "  )\n",
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-04 16:17:42,999 [MainThread          ] [DEBUG]  Read file=\"/content/drive/My Drive/datasets/corpus/labeled/corpus-batch-0-mturk.csv\" with 200 rows.\n",
            "2020-07-04 16:17:43,013 [MainThread          ] [DEBUG]  Read file=\"/content/drive/My Drive/datasets/corpus/labeled/corpus-batch-2-mturk.csv\" with 194 rows.\n",
            "2020-07-04 16:17:43,026 [MainThread          ] [DEBUG]  Read file=\"/content/drive/My Drive/datasets/corpus/labeled/corpus-batch-3-mturk.csv\" with 198 rows.\n",
            "2020-07-04 16:17:43,039 [MainThread          ] [DEBUG]  Read file=\"/content/drive/My Drive/datasets/corpus/labeled/corpus-batch-4-mturk.csv\" with 196 rows.\n",
            "2020-07-04 16:17:43,057 [MainThread          ] [INFO ]  Build confusion matrix.\n",
            "2020-07-04 16:17:43,236 [MainThread          ] [INFO ]  Dropped 180 requirements due to ties.\n",
            "2020-07-04 16:17:43,240 [MainThread          ] [INFO ]  Built confusion matrix including 214 of 394 requirements. \n",
            "2020-07-04 16:17:43,245 [MainThread          ] [INFO ]  Overall \"vague\" votes count = 96. Overall \"not vague\" votes count = 332\n",
            "2020-07-04 16:17:43,266 [MainThread          ] [INFO ]  \"vague\" majority label count = 48. \"not vague\" majority label count = 166.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: False",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-3fcc0ff38659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   )\n\u001b[1;32m     25\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requirement'\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m'Conformance tests described in clause 5.3.6 shall be carried out.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: False"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1jPjv_sv1QE",
        "colab_type": "text"
      },
      "source": [
        "### Split data set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4a9O2w4v04v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "87430a6a-43d3-49df-ac85-45f2ace0a76a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, List\n",
        "from ktrain import text as txt\n",
        "\n",
        "\n",
        "def split_dataset(dataframe: pd.DataFrame) -> Tuple[List[str], List[int], List[str], List[int], List[str], List[int]]:\n",
        "    \"\"\"\n",
        "    Split the dataset into training, validation and test set.\n",
        "\n",
        "    Args:\n",
        "        data_frame (pd.DataFrame): The data frame to generate the data sets from.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[int], List[str], List[int], List[str], List[int]]: x_train, y_train, x_val, y_val, x_test, y_test\n",
        "    \"\"\"\n",
        "    train_df, val_test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE, stratify=df['majority_label'])\n",
        "    val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=RANDOM_STATE, stratify=val_test_df['majority_label'])\n",
        "\n",
        "    print(f'Training dataset: vague count=\"{train_df.sum()[\"majority_label\"]}\", not vague count=\"{train_df.shape[0] - train_df.sum()[\"majority_label\"]}\"')\n",
        "    print(f'Validation dataset: vague count=\"{val_df.sum()[\"majority_label\"]}\", not vague count=\"{val_df.shape[0] - val_df.sum()[\"majority_label\"]}\"')\n",
        "    print(f'Test dataset: vague count=\"{test_df.sum()[\"majority_label\"]}\", not vague count=\"{test_df.shape[0] - test_df.sum()[\"majority_label\"]}\"')\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "\n",
        "def preprocess_data(train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple:\n",
        "    def _preprocess(my_df: pd.DataFrame) -> Tuple:\n",
        "        dummy_df = pd.DataFrame.from_dict({'requirement': ['foo', 'bar'], 'majority_label': [0, 1]})\n",
        "        return txt.texts_from_df(my_df, text_column='requirement', label_columns=['majority_label'], val_df=dummy_df,  max_features=MAX_FEATURES, maxlen=MAX_LEN,  ngram_range=NGRAM_RANGE, preprocess_mode=PREPROCESS_MODE, random_state=RANDOM_STATE)\n",
        "    \n",
        "    train_data, _, _ = _preprocess(train_df)\n",
        "    val_data, _, _ = _preprocess(val_df)\n",
        "    test_data, _, test_preproc = _preprocess(test_df)\n",
        "\n",
        "    return train_data, val_data, test_data, test_preproc\n",
        "\n",
        "# Split the data set\n",
        "train_df, val_df, test_df = split_dataset(df)\n",
        "\n",
        "# Preprocess for Transfer Learning\n",
        "train_data, val_data, test_data, test_preproc = preprocess_data(train_df, val_df, test_df)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset: vague count=\"38\", not vague count=\"133\"\n",
            "Validation dataset: vague count=\"5\", not vague count=\"16\"\n",
            "Test dataset: vague count=\"5\", not vague count=\"17\"\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 21\n",
            "\t95percentile : 40\n",
            "\t99percentile : 63\n",
            "2020-07-04 16:27:08,838 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "2020-07-04 16:27:09,013 [MainThread          ] [DEBUG]  https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1\" 200 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 1\n",
            "\t95percentile : 1\n",
            "\t99percentile : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ktrain/text/preprocessor.py:229: UserWarning: List or array of two texts supplied, so task being treated as text classification. If this is a sentence pair classification task, please cast to tuple.\n",
            "  'If this is a sentence pair classification task, please cast to tuple.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 22\n",
            "\t95percentile : 38\n",
            "\t99percentile : 46\n",
            "2020-07-04 16:27:09,367 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "2020-07-04 16:27:09,546 [MainThread          ] [DEBUG]  https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1\" 200 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 1\n",
            "\t95percentile : 1\n",
            "\t99percentile : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 21\n",
            "\t95percentile : 36\n",
            "\t99percentile : 38\n",
            "2020-07-04 16:27:09,782 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "2020-07-04 16:27:09,951 [MainThread          ] [DEBUG]  https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1\" 200 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 1\n",
            "\t95percentile : 1\n",
            "\t99percentile : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe5xxVPrb4IO",
        "colab_type": "text"
      },
      "source": [
        "## STEP 1:  Preprocess Data and Create a Transformer Model\n",
        "\n",
        "We will use [DistilBERT](https://arxiv.org/abs/1910.01108)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GkeZCUozM2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "50797b59-be5c-4af3-816d-a3ff27073a5e"
      },
      "source": [
        "import ktrain\n",
        "t = txt.Transformer(MODEL_NAME, maxlen=MAX_LEN, class_names=['not-vague', 'vague']) # 0=not-vague 1=vague\n",
        "t.preprocess_train_called = True # Simulate call to preprocess_train()\n",
        "# t.preprocess_train(['foo', 'bar'], [0, 1]) \n",
        "# val_data = t.preprocess_test(x_val, y_val)\n",
        "# test_data = t.preprocess_test(x_test, y_test)\n",
        "\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=train_data, val_data=val_data, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-04 16:45:04,282 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "2020-07-04 16:45:04,427 [MainThread          ] [DEBUG]  https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/distilbert-base-uncased-config.json HTTP/1.1\" 200 0\n",
            "2020-07-04 16:45:04,434 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): cdn.huggingface.co:443\n",
            "2020-07-04 16:45:04,697 [MainThread          ] [DEBUG]  https://cdn.huggingface.co:443 \"HEAD /distilbert-base-uncased-tf_model.h5 HTTP/1.1\" 200 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4sGPJgOcBTd",
        "colab_type": "text"
      },
      "source": [
        "## STEP 2:  Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_nH_F9yYvCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "cf5fd46a-0814-4fe7-d9bb-048b96c6e3e5"
      },
      "source": [
        "learner.fit_onecycle(LEARNING_RATE, EPOCHS)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 5e-05...\n",
            "Train for 29 steps, validate for 1 steps\n",
            "Epoch 1/4\n",
            "29/29 [==============================] - 31s 1s/step - loss: 0.5864 - accuracy: 0.7485 - val_loss: 0.5537 - val_accuracy: 0.7619\n",
            "Epoch 2/4\n",
            "29/29 [==============================] - 20s 687ms/step - loss: 0.5039 - accuracy: 0.7778 - val_loss: 0.6169 - val_accuracy: 0.7619\n",
            "Epoch 3/4\n",
            "29/29 [==============================] - 20s 688ms/step - loss: 0.4829 - accuracy: 0.7836 - val_loss: 0.5690 - val_accuracy: 0.7619\n",
            "Epoch 4/4\n",
            "29/29 [==============================] - 20s 688ms/step - loss: 0.3085 - accuracy: 0.8655 - val_loss: 0.6800 - val_accuracy: 0.7143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6dde9aa550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho6eSo9IcI3_",
        "colab_type": "text"
      },
      "source": [
        "## STEP 3: Evaluate and Inspect the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvcxCvLOcOje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "e9528b01-f339-493e-93c3-2d0acfcb8c0d"
      },
      "source": [
        "test_result = learner.validate(class_names=t.get_classes(), val_data=test_data)\n",
        "print(test_result)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   not-vague       0.79      0.88      0.83        17\n",
            "       vague       0.33      0.20      0.25         5\n",
            "\n",
            "    accuracy                           0.73        22\n",
            "   macro avg       0.56      0.54      0.54        22\n",
            "weighted avg       0.69      0.73      0.70        22\n",
            "\n",
            "[[15  2]\n",
            " [ 4  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhG3fPtPcVKe",
        "colab_type": "text"
      },
      "source": [
        "Let's examine the validation example about which we were the most wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCABLebacTWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5b062ee9-2bc9-465c-9a60-5f1e265fd12d"
      },
      "source": [
        "learner.view_top_losses(preproc=t)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "id:6 | loss:3.12 | true:vague | pred:not-vague)\n",
            "\n",
            "----------\n",
            "id:0 | loss:2.69 | true:vague | pred:not-vague)\n",
            "\n",
            "----------\n",
            "id:9 | loss:2.48 | true:vague | pred:not-vague)\n",
            "\n",
            "----------\n",
            "id:11 | loss:1.67 | true:vague | pred:not-vague)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHYRBdBycfne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "06127f71-9b11-40b7-f917-1d8e4f761ff4"
      },
      "source": [
        "top_loss_req = test_df.iloc[[6]]['requirement'] # Requirement that produces top loss\n",
        "print(top_loss_req)\n",
        "print(test_df.iloc[9]['majority_label'])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23    Conformance tests described in clause 5.3.6 sh...\n",
            "Name: requirement, dtype: object\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUBegwcKcyEG",
        "colab_type": "text"
      },
      "source": [
        "This post talks more about computing than `alt.atheism` (the true category), so our model placed it into the only computing category available to it: `comp.graphics`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vbRyh4Wyk8Q",
        "colab_type": "text"
      },
      "source": [
        "## STEP 3.1: Gather Results\n",
        "\n",
        "Gather results and write them to the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dYROS_Tyqs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a56e5fb6-bf1a-4fe2-faee-d5993047f35b"
      },
      "source": [
        "from vaguerequirementslib import TP, TN, FP, FN, calc_all_metrics\n",
        "result_data = {\n",
        "    'metrics':{\n",
        "        'vague': {\n",
        "            TP: test_result[1][1],\n",
        "            FP: test_result[0][1],\n",
        "            TN: test_result[0][0],\n",
        "            FN: test_result[1][0]\n",
        "        },\n",
        "        'not_vague': {\n",
        "            TP: test_result[0][0],\n",
        "            FP: test_result[1][0],\n",
        "            TN: test_result[1][1],\n",
        "            FN: test_result[0][1]\n",
        "        }\n",
        "    },\n",
        "    'misc': {   \n",
        "        'data_files': DATA_FILE_NAMES,\n",
        "        'random_state': RANDOM_STATE\n",
        "    },\n",
        "    'hyperparameter': {\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'epochs': EPOCHS\n",
        "        'model_name': MODEL_NAME,\n",
        "        'max_len': MAX_LEN,\n",
        "        'batch_size': BATCH_SIZE\n",
        "        # 'max_features': MAX_FEATURES,\n",
        "        # 'ngram_range': NGRAM_RANGE\n",
        "    }\n",
        "}\n",
        "result_data['metrics']['not_vague'].update(calc_all_metrics(**result_data['metrics']['not_vague']))\n",
        "result_data['metrics']['vague'].update(calc_all_metrics(**result_data['metrics']['vague']))\n",
        "print(result_data)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'metrics': {'vague': {'true_positive': 4, 'false_positive': 13, 'true_negative': 4, 'false_negative': 1, 'accuracy': 0.36363636363636365, 'precision': 0.23529411764705882, 'recall': 0.8, 'specificity': 0.23529411764705882, 'false_negative_rate': 0.2, 'false_positive_rate': 0.7647058823529411, 'f1_score': 0.3636363636363636}, 'not_vague': {'true_positive': 4, 'false_positive': 1, 'true_negative': 4, 'false_negative': 13, 'accuracy': 0.36363636363636365, 'precision': 0.8, 'recall': 0.23529411764705882, 'specificity': 0.8, 'false_negative_rate': 0.7647058823529411, 'false_positive_rate': 0.2, 'f1_score': 0.3636363636363636}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcZQ6HbqdMcF",
        "colab_type": "text"
      },
      "source": [
        "## STEP 4: Making Predictions on New Data in Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp8tw3Y0cnJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc=test_preproc)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZOeu9cDdguM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3774a6a2-dec7-42b8-be2e-f9d42ad60b58"
      },
      "source": [
        "predictor.predict(top_loss_req)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuMmx8f5dr45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dff8f8cc-3821-467e-987c-7c66d4c4051b"
      },
      "source": [
        "# predicted probability scores for each category\n",
        "predictor.predict_proba(top_loss_req)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9278868 , 0.07211317], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldxX1mtLd3Nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42eddab8-0c71-46dd-9c09-d1e9ae8d44dd"
      },
      "source": [
        "predictor.get_classes()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not-vague', 'vague']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tHos7V6d8RQ",
        "colab_type": "text"
      },
      "source": [
        "As expected, `soc.religion.christian` is assigned the highest probability.\n",
        "\n",
        "Let's invoke the `explain` method to see which words contribute most to the classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HgZDLYUeVaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "15e598db-8c35-415c-85bf-1866b0ca90dc"
      },
      "source": [
        "predictor.explain(top_loss_req)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=vague\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.770</b>, score <b>1.207</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.519\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.40%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.312\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.867\">conformance</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.99%); opacity: 0.85\" title=\"0.214\">tests</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.57%); opacity: 0.81\" title=\"0.064\">described</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.64%); opacity: 0.80\" title=\"0.015\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.25%); opacity: 0.94\" title=\"0.623\">clause</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.85%); opacity: 0.91\" title=\"0.472\">5</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 81.59%); opacity: 0.87\" title=\"0.286\">3</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 92.09%); opacity: 0.82\" title=\"0.086\">6</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.08%); opacity: 0.85\" title=\"-0.212\">shall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.52%); opacity: 0.88\" title=\"-0.357\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.76%); opacity: 0.93\" title=\"0.581\">carried</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.27%); opacity: 0.96\" title=\"0.679\">out</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcph2bSLe5cW",
        "colab_type": "text"
      },
      "source": [
        "The words in the darkest shade of green contribute most to the classification and agree with what you would expect for this example.\n",
        "\n",
        "We can save and reload our predictor for later deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1nzxI_Jec-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor.save('/tmp/my_distilbert_predictor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDEU2s03fHsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded_predictor = ktrain.load_predictor('/tmp/my_distilbert_predictor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4R1r12rgNlI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1bd96ed0-4d5d-480d-cc01-e9a2993bf204"
      },
      "source": [
        "reloaded_predictor.predict('My computer monitor is really blurry.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'comp.graphics'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCJgsiUzg1wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}