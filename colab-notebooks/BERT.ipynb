{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vague-requirements-bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaaLeo/vague-requirements-scripts/blob/master/colab-notebooks/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgfHNcOPbOk3",
        "colab_type": "text"
      },
      "source": [
        "# Classify requirements as vague or not using [ktrain](https://github.com/amaiya/ktrain) and tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jOLkB2Gyq4e",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies\n",
        "*ktrain* requires TensorFlow 2.1. See [amaiya/ktrain#151](https://github.com/amaiya/ktrain/issues/151).\n",
        "Further we install a forked version of eli5lib to gain insights in the model's decision process and some self built helper functions to preprocess MTurk result files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDBNS4iNXuUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d1fa8180-785a-4184-9d05-3419b8d7a72a"
      },
      "source": [
        "!pip3 install -q tensorflow_gpu==2.1.0 ktrain==0.17.3\n",
        "!pip3 install -q -U git+https://github.com/HaaLeo/vague-requirements-scripts\n",
        "!pip3 install -q git+https://github.com/amaiya/eli5@tfkeras_0_10_1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for vaguerequirementslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e1XeYJg3e_8",
        "colab_type": "text"
      },
      "source": [
        "Check versions and enable logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAA46kq4X0C_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import ktrain\n",
        "assert tf.__version__ == '2.1.0'\n",
        "assert ktrain.__version__ == '0.17.3'\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s [%(threadName)-20.20s] [%(levelname)-5.5s]  %(message)s',\n",
        "    stream=sys.stdout,\n",
        "    level=logging.DEBUG)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-2kIx7PwCR5",
        "colab_type": "text"
      },
      "source": [
        "## Set Parameters\n",
        "Set the parameters for this run.\n",
        "Ktrain ignores `max_features` and `ngram_range` in v0.17.3, see [amaiya/ktrain/issues#190](https://github.com/amaiya/ktrain/issues/190)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF_VXFLkwC1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices_to_read = [0,2,3,4] # indicate which MTurk files shall be read.\n",
        "DATA_FILE_NAMES = [f'corpus-batch-{i}-mturk.csv' for i in indices_to_read]\n",
        "\n",
        "RANDOM_STATE = 1 # for seeding\n",
        "\n",
        "LEARNING_RATE = 5e-5\n",
        "EPOCHS = 4\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 6\n",
        "MAX_FEATURES = 35_000\n",
        "NGRAM_RANGE = 1\n",
        "\n",
        "CLASS_NAMES = ['not-vague', 'vague'] # 0=not-vague 1=vague\n",
        "\n",
        "PREPROCESS_MODE = 'distilbert'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdk5lPu3bxze",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl9XSystzRQs",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive\n",
        "Mount the google drive to access the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPQxmvhazWoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2563718d-a92b-40c5-d484-b993919f68c7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4XQHRbHzbb_",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataset Into Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL5yXifL0SEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "10beae35-b3a4-447c-86e2-33239b05aee5"
      },
      "source": [
        "from vaguerequirementslib import read_csv_files, build_confusion_matrix, calc_majority_label\n",
        "import pandas as pd\n",
        "\n",
        "def read_drive_data(files_list: list, separator: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate the majority label for the given source file list\n",
        "\n",
        "    Args:\n",
        "        files_list (list): The CSV files to calculate the majority label for\n",
        "        separator (str): The CSV separator\n",
        "        drop_ties (bool): If there is a tie in votes (e.g.: One votes for vague one for not vague) then drop this entry from the confusion matrix.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The dataframe containing the majority label.\n",
        "    \"\"\"\n",
        "    df = read_csv_files(files_list, separator)\n",
        "    confusion_matrix = build_confusion_matrix(df, drop_ties=True)\n",
        "    return calc_majority_label(confusion_matrix)\n",
        "\n",
        "# Read all data\n",
        "df = read_drive_data(\n",
        "    [f'/content/drive/My Drive/datasets/corpus/labeled/{file_name}' for file_name in DATA_FILE_NAMES],\n",
        "    ','\n",
        "  )\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-05 08:38:12,869 [MainThread          ] [DEBUG]  Read file=\"/content/drive/My Drive/datasets/corpus/labeled/corpus-batch-0-mturk.csv\" with 200 rows.\n",
            "2020-07-05 08:38:12,882 [MainThread          ] [DEBUG]  Read file=\"/content/drive/My Drive/datasets/corpus/labeled/corpus-batch-2-mturk.csv\" with 194 rows.\n",
            "2020-07-05 08:38:12,895 [MainThread          ] [DEBUG]  Read file=\"/content/drive/My Drive/datasets/corpus/labeled/corpus-batch-3-mturk.csv\" with 198 rows.\n",
            "2020-07-05 08:38:12,908 [MainThread          ] [DEBUG]  Read file=\"/content/drive/My Drive/datasets/corpus/labeled/corpus-batch-4-mturk.csv\" with 196 rows.\n",
            "2020-07-05 08:38:12,921 [MainThread          ] [INFO ]  Build confusion matrix.\n",
            "2020-07-05 08:38:13,027 [MainThread          ] [INFO ]  Dropped 180 requirements due to ties.\n",
            "2020-07-05 08:38:13,029 [MainThread          ] [INFO ]  Built confusion matrix including 214 of 394 requirements. \n",
            "2020-07-05 08:38:13,032 [MainThread          ] [INFO ]  Overall \"vague\" votes count = 96. Overall \"not vague\" votes count = 332\n",
            "2020-07-05 08:38:13,051 [MainThread          ] [INFO ]  \"vague\" majority label count = 48. \"not vague\" majority label count = 166.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>requirement</th>\n",
              "      <th>vague_count</th>\n",
              "      <th>not_vague_count</th>\n",
              "      <th>majority_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A fallback per band feature set resulting from...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actuation of steering shall be possible regard...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Additionally, the ZigBee end device shall then...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Additionally, the plan provides traceability f...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After completion of release of the resources, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         requirement  ...  majority_label\n",
              "0  A fallback per band feature set resulting from...  ...               1\n",
              "1  Actuation of steering shall be possible regard...  ...               0\n",
              "2  Additionally, the ZigBee end device shall then...  ...               0\n",
              "3  Additionally, the plan provides traceability f...  ...               1\n",
              "4  After completion of release of the resources, ...  ...               0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1jPjv_sv1QE",
        "colab_type": "text"
      },
      "source": [
        "### Split data set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4a9O2w4v04v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "88e89e04-781d-4bb6-f999-6b5485998cef"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, List\n",
        "from ktrain import text as txt\n",
        "\n",
        "\n",
        "def split_dataset(dataframe: pd.DataFrame) -> Tuple[List[str], List[int], List[str], List[int], List[str], List[int]]:\n",
        "    \"\"\"\n",
        "    Split the dataset into training, validation and test set.\n",
        "\n",
        "    Args:\n",
        "        data_frame (pd.DataFrame): The data frame to generate the data sets from.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], List[int], List[str], List[int], List[str], List[int]]: x_train, y_train, x_val, y_val, x_test, y_test\n",
        "    \"\"\"\n",
        "    train_df, val_test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE, stratify=df['majority_label'])\n",
        "    val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=RANDOM_STATE, stratify=val_test_df['majority_label'])\n",
        "\n",
        "    print(f'Training dataset: vague count=\"{train_df.sum()[\"majority_label\"]}\", not vague count=\"{train_df.shape[0] - train_df.sum()[\"majority_label\"]}\"')\n",
        "    print(f'Validation dataset: vague count=\"{val_df.sum()[\"majority_label\"]}\", not vague count=\"{val_df.shape[0] - val_df.sum()[\"majority_label\"]}\"')\n",
        "    print(f'Test dataset: vague count=\"{test_df.sum()[\"majority_label\"]}\", not vague count=\"{test_df.shape[0] - test_df.sum()[\"majority_label\"]}\"')\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "\n",
        "def preprocess_data(train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple:\n",
        "    def _preprocess(my_df: pd.DataFrame) -> Tuple:\n",
        "        dummy_df = pd.DataFrame.from_dict({'requirement': ['foo', 'bar'], 'majority_label': [0, 1]})\n",
        "        return txt.texts_from_df(my_df, text_column='requirement', label_columns=['majority_label'], val_df=dummy_df,  max_features=MAX_FEATURES, maxlen=MAX_LEN,  ngram_range=NGRAM_RANGE, preprocess_mode=PREPROCESS_MODE, random_state=RANDOM_STATE)\n",
        "    \n",
        "    train_data, _, _ = _preprocess(train_df)\n",
        "    val_data, _, _ = _preprocess(val_df)\n",
        "    test_data, _, test_preproc = _preprocess(test_df)\n",
        "\n",
        "    return train_data, val_data, test_data, test_preproc\n",
        "\n",
        "# Split the data set\n",
        "train_df, val_df, test_df = split_dataset(df)\n",
        "\n",
        "# Preprocess for Transfer Learning\n",
        "train_data, val_data, test_data, test_preproc = preprocess_data(train_df, val_df, test_df)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset: vague count=\"38\", not vague count=\"133\"\n",
            "Validation dataset: vague count=\"5\", not vague count=\"16\"\n",
            "Test dataset: vague count=\"5\", not vague count=\"17\"\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 21\n",
            "\t95percentile : 40\n",
            "\t99percentile : 63\n",
            "2020-07-05 08:38:15,972 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "2020-07-05 08:38:16,249 [MainThread          ] [DEBUG]  https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1\" 200 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 1\n",
            "\t95percentile : 1\n",
            "\t99percentile : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ktrain/text/preprocessor.py:229: UserWarning: List or array of two texts supplied, so task being treated as text classification. If this is a sentence pair classification task, please cast to tuple.\n",
            "  'If this is a sentence pair classification task, please cast to tuple.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 22\n",
            "\t95percentile : 38\n",
            "\t99percentile : 46\n",
            "2020-07-05 08:38:16,522 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "2020-07-05 08:38:16,791 [MainThread          ] [DEBUG]  https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1\" 200 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 1\n",
            "\t95percentile : 1\n",
            "\t99percentile : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 21\n",
            "\t95percentile : 36\n",
            "\t99percentile : 38\n",
            "2020-07-05 08:38:16,961 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "2020-07-05 08:38:17,227 [MainThread          ] [DEBUG]  https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/bert-base-uncased-vocab.txt HTTP/1.1\" 200 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 1\n",
            "\t95percentile : 1\n",
            "\t99percentile : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe5xxVPrb4IO",
        "colab_type": "text"
      },
      "source": [
        "## STEP 1:  Create a Transformer Model and Train it\n",
        "\n",
        "We will use [DistilBERT](https://arxiv.org/abs/1910.01108)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GkeZCUozM2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "c43700b5-84ab-4bea-c9f2-3f16e4dec020"
      },
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "# Create the transformer\n",
        "t = txt.Transformer(MODEL_NAME, maxlen=MAX_LEN, class_names=CLASS_NAMES)\n",
        "t.preprocess_train_called = True # Simulate call to preprocess_train()\n",
        "\n",
        "# Get the model and learner\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=train_data, val_data=val_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "# For every triggered fitting run create a new directory where the results will be saved\n",
        "now = datetime.now(timezone('Europe/Berlin'))\n",
        "result_dir = f'/content/drive/My Drive/runs/{now.strftime(\"%Y-%m-%d/%H-%M-%S\")}'\n",
        "\n",
        "# Fit the model\n",
        "learner.fit_onecycle(LEARNING_RATE, EPOCHS)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-05 09:14:25,208 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
            "2020-07-05 09:14:25,480 [MainThread          ] [DEBUG]  https://s3.amazonaws.com:443 \"HEAD /models.huggingface.co/bert/distilbert-base-uncased-config.json HTTP/1.1\" 200 0\n",
            "2020-07-05 09:14:25,484 [MainThread          ] [DEBUG]  Starting new HTTPS connection (1): cdn.huggingface.co:443\n",
            "2020-07-05 09:14:25,704 [MainThread          ] [DEBUG]  https://cdn.huggingface.co:443 \"HEAD /distilbert-base-uncased-tf_model.h5 HTTP/1.1\" 200 0\n",
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 5e-05...\n",
            "Train for 29 steps, validate for 1 steps\n",
            "Epoch 1/4\n",
            "29/29 [==============================] - 14s 492ms/step - loss: 0.6013 - accuracy: 0.7427 - val_loss: 0.5583 - val_accuracy: 0.7619\n",
            "Epoch 2/4\n",
            "29/29 [==============================] - 7s 234ms/step - loss: 0.5362 - accuracy: 0.7778 - val_loss: 0.5399 - val_accuracy: 0.7619\n",
            "Epoch 3/4\n",
            "29/29 [==============================] - 7s 235ms/step - loss: 0.3843 - accuracy: 0.7953 - val_loss: 0.6033 - val_accuracy: 0.7619\n",
            "Epoch 4/4\n",
            "29/29 [==============================] - 7s 234ms/step - loss: 0.2154 - accuracy: 0.9181 - val_loss: 0.5703 - val_accuracy: 0.6190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho6eSo9IcI3_",
        "colab_type": "text"
      },
      "source": [
        "## STEP 2: Evaluate the model\n",
        "Evaluate the model using the `test_data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvcxCvLOcOje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "075b348c-17c6-41fc-e862-7b822ea61886"
      },
      "source": [
        "test_result = learner.validate(class_names=t.get_classes(), val_data=test_data)\n",
        "print(test_result)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   not-vague       0.79      0.65      0.71        17\n",
            "       vague       0.25      0.40      0.31         5\n",
            "\n",
            "    accuracy                           0.59        22\n",
            "   macro avg       0.52      0.52      0.51        22\n",
            "weighted avg       0.66      0.59      0.62        22\n",
            "\n",
            "[[11  6]\n",
            " [ 3  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vbRyh4Wyk8Q",
        "colab_type": "text"
      },
      "source": [
        "## STEP 3: Gather Results\n",
        "\n",
        "Gather results, calulate metrics and write them to the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dYROS_Tyqs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "from os import path\n",
        "\n",
        "from vaguerequirementslib import TP, TN, FP, FN, calc_all_metrics\n",
        "\n",
        "def build_result_data(test_result: List) -> dict:\n",
        "    result_data = {\n",
        "        'metrics':{\n",
        "            'vague': {\n",
        "                TP: int(test_result[1][1]),\n",
        "                FP: int(test_result[0][1]),\n",
        "                TN: int(test_result[0][0]),\n",
        "                FN: int(test_result[1][0])\n",
        "            },\n",
        "            'not_vague': {\n",
        "                TP: int(test_result[0][0]),\n",
        "                FP: int(test_result[1][0]),\n",
        "                TN: int(test_result[1][1]),\n",
        "                FN: int(test_result[0][1])\n",
        "            }\n",
        "        },\n",
        "        'misc': {   \n",
        "            'data_files': DATA_FILE_NAMES,\n",
        "            'random_state': RANDOM_STATE\n",
        "        },\n",
        "        'hyperparameter': {\n",
        "            'learning_rate': LEARNING_RATE,\n",
        "            'epochs': EPOCHS,\n",
        "            'model_name': MODEL_NAME,\n",
        "            'max_len': MAX_LEN,\n",
        "            'batch_size': BATCH_SIZE,\n",
        "            'max_features': MAX_FEATURES,\n",
        "            'ngram_range': NGRAM_RANGE\n",
        "        }\n",
        "    }\n",
        "    result_data['metrics']['not_vague'].update(calc_all_metrics(**result_data['metrics']['not_vague']))\n",
        "    result_data['metrics']['vague'].update(calc_all_metrics(**result_data['metrics']['vague']))\n",
        "    \n",
        "    return result_data\n",
        "\n",
        "result_data = build_result_data(test_result)\n",
        "# Get the predictor\n",
        "predictor = ktrain.get_predictor(learner.model, preproc=t)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdbYfab8cEVu",
        "colab_type": "text"
      },
      "source": [
        "## STEP 3.1 Save the Results\n",
        "Check out the [FAQ](https://github.com/amaiya/ktrain/blob/master/FAQ.md#method-1-using-predictor-api-works-for-any-model) for how to load a model from a predictor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF3XGeIecKer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the evaluation result (test_data results)\n",
        "with open(path.join(result_dir, 'evaluation.json'), mode='w', encoding='utf-8') as json_file:\n",
        "    json.dump(result_data, json_file, indent=4)\n",
        "\n",
        "# Save the corresponding model (predictor)\n",
        "predictor.save(path.join(result_dir, 'predictor'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIuTq8eqdXws",
        "colab_type": "text"
      },
      "source": [
        "## STEP 4 Inspect the Model and its Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhG3fPtPcVKe",
        "colab_type": "text"
      },
      "source": [
        "Let's examine the validation example about which we were the most wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCABLebacTWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "b3442a23-f884-4ab6-9193-937ffb514fe0"
      },
      "source": [
        "learner.view_top_losses(n=4, preproc=t, val_data=test_data)\n",
        "top_losses = learner.top_losses(n=4, preproc=t, val_data=test_data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "id:0 | loss:2.57 | true:vague | pred:not-vague)\n",
            "\n",
            "----------\n",
            "id:20 | loss:2.08 | true:vague | pred:not-vague)\n",
            "\n",
            "----------\n",
            "id:4 | loss:1.44 | true:vague | pred:not-vague)\n",
            "\n",
            "----------\n",
            "id:6 | loss:1.14 | true:not-vague | pred:vague)\n",
            "\n",
            "[(0, 2.568476, 'vague', 'not-vague'), (20, 2.0769691, 'vague', 'not-vague'), (4, 1.4417335, 'vague', 'not-vague'), (6, 1.135456, 'not-vague', 'vague')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuMmx8f5dr45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "676aa706-02f4-415f-d6e2-00651598242b"
      },
      "source": [
        "top_loss_req = test_df.iloc[6]['requirement'] # Requirement that produces top loss\n",
        "\n",
        "print(predictor.predict(top_loss_req))\n",
        "\n",
        "# predicted probability scores for each category\n",
        "print(predictor.predict_proba(top_loss_req))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "vague\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.3212756 0.6787244]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tHos7V6d8RQ",
        "colab_type": "text"
      },
      "source": [
        "Let's invoke the `explain` method to see which words contribute most to the classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HgZDLYUeVaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "8004dc57-3ccf-409e-dcf5-dffb699b6bc8"
      },
      "source": [
        "from IPython.core.display import display\n",
        "\n",
        "for id, _, _, _ in top_losses:\n",
        "    top_loss_req = test_df.iloc[id]['requirement'] # Requirement that produces top loss\n",
        "    display(predictor.explain(top_loss_req, n_samples=1_000))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not-vague\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.827</b>, score <b>-1.564</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.201\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.36%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.362\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 89.86%); opacity: 0.83\" title=\"0.128\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.73%); opacity: 0.85\" title=\"0.208\">hardware</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.88%); opacity: 0.82\" title=\"-0.110\">processed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.45%); opacity: 0.81\" title=\"0.041\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.09%); opacity: 0.82\" title=\"-0.106\">water</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.20%); opacity: 0.80\" title=\"0.003\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.28%); opacity: 0.84\" title=\"-0.176\">moisture</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.71%); opacity: 0.87\" title=\"-0.320\">content</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.54%); opacity: 0.82\" title=\"-0.082\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.55%); opacity: 0.85\" title=\"-0.212\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.99%); opacity: 0.84\" title=\"-0.182\">gas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.51%); opacity: 0.89\" title=\"-0.424\">effluent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.54%); opacity: 0.85\" title=\"-0.212\">through</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.29%); opacity: 0.81\" title=\"-0.056\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.02%); opacity: 0.85\" title=\"-0.223\">over</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.45%); opacity: 0.81\" title=\"-0.054\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.06%); opacity: 0.82\" title=\"-0.090\">dried</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.98%); opacity: 0.90\" title=\"-0.437\">components</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 74.78%); opacity: 0.90\" title=\"-0.469\">parts</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.25%); opacity: 0.87\" title=\"-0.307\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.62%); opacity: 0.83\" title=\"-0.132\">system</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.07%); opacity: 0.85\" title=\"-0.243\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.56%); opacity: 0.82\" title=\"-0.082\">ambient</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.05%); opacity: 0.85\" title=\"0.244\">temperature</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.907\">shall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.02%); opacity: 0.80\" title=\"-0.022\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.85%); opacity: 0.83\" title=\"-0.128\">measured</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not-vague\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.817</b>, score <b>-1.494</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.873\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 84.22%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.622\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 97.11%); opacity: 0.80\" title=\"-0.026\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.76%); opacity: 0.90\" title=\"-0.568\">service</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.19%); opacity: 0.83\" title=\"-0.169\">provider</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.77%); opacity: 0.91\" title=\"0.600\">shall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.85%); opacity: 0.83\" title=\"0.155\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.33%); opacity: 0.81\" title=\"-0.067\">able</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.47%); opacity: 0.83\" title=\"-0.141\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.80%); opacity: 0.80\" title=\"0.017\">configure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.36%); opacity: 0.95\" title=\"-0.820\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.097\">state</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.29%); opacity: 0.94\" title=\"-0.787\">changes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.83%); opacity: 0.82\" title=\"0.113\">shall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.98%); opacity: 0.90\" title=\"0.561\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.20%); opacity: 0.83\" title=\"0.192\">notified</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.26%); opacity: 0.81\" title=\"0.037\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.00%); opacity: 0.81\" title=\"-0.073\">well</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.10%); opacity: 0.80\" title=\"0.014\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.92%); opacity: 0.85\" title=\"-0.298\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.45%); opacity: 0.84\" title=\"-0.209\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.90%); opacity: 0.81\" title=\"-0.058\">recipient</span><span style=\"opacity: 0.80\">(</span><span style=\"background-color: hsl(120, 100.00%, 78.49%); opacity: 0.88\" title=\"0.452\">s</span><span style=\"opacity: 0.80\">) (</span><span style=\"background-color: hsl(120, 100.00%, 78.25%); opacity: 0.88\" title=\"0.460\">see</span><span style=\"opacity: 0.80\"> ).</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not-vague\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.764</b>, score <b>-1.177</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.828\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.08%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.349\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 83.32%); opacity: 0.86\" title=\"-0.291\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.92%); opacity: 0.84\" title=\"0.205\">test</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.85%); opacity: 0.93\" title=\"0.677\">shall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.25%); opacity: 0.86\" title=\"0.317\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.95%); opacity: 0.83\" title=\"-0.161\">performed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.080\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.99%); opacity: 0.83\" title=\"-0.140\">qualification</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.014\">protoqualification</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 79.30%); opacity: 0.88\" title=\"0.395\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.69%); opacity: 0.82\" title=\"0.126\">acceptance</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.17%); opacity: 0.86\" title=\"0.320\">testing</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=vague\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.781</b>, score <b>1.270</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.568\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.75%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.298\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.030\">conformance</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.98%); opacity: 0.87\" title=\"0.356\">tests</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.76%); opacity: 0.84\" title=\"0.212\">described</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.66%); opacity: 0.87\" title=\"0.365\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.64%); opacity: 0.92\" title=\"0.599\">clause</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.96%); opacity: 0.85\" title=\"0.255\">5</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 89.54%); opacity: 0.83\" title=\"0.151\">3</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.58%); opacity: 0.81\" title=\"0.075\">6</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.05%); opacity: 0.85\" title=\"-0.253\">shall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.47%); opacity: 0.83\" title=\"-0.174\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.30%); opacity: 0.88\" title=\"0.402\">carried</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.84%); opacity: 0.96\" title=\"0.822\">out</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcph2bSLe5cW",
        "colab_type": "text"
      },
      "source": [
        "The words in the darkest shade of green contribute most to the classification and agree with what you would expect for this example."
      ]
    }
  ]
}